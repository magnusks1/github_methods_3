---
title: "practical_exercise_2, Methods 3, 2021, autumn semester"
author: 'Anja, Astrid, Jessica, Juli, Magnus'
date: "22 sep 2021"
output: pdf_document
---

<style type="text/css">
  body{
  font-size: 14pt;
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse, lme4, MuMIn)
```

# Assignment 1: Using mixed effects modelling to model hierarchical data
In this assignment we will be investigating the _politeness_ dataset of Winter and Grawunder (2012) and apply basic methods of multilevel modelling. 

## Dataset
The dataset has been shared on GitHub, so make sure that the csv-file is on your current path. Otherwise you can supply the full path.

```{r}
politeness <- read.csv('politeness.csv') ## read in data
```

# Exercises and objectives
The objectives of the exercises of this assignment are:  
1) Learning to recognize hierarchical structures within datasets and describing them  
2) Creating simple multilevel models and assessing their fitness  
3) Write up a report about the findings of the study  

REMEMBER: In your report, make sure to include code that can reproduce the answers requested in the exercises below  
REMEMBER: This assignment will be part of your final portfolio

## Exercise 1 - describing the dataset and making some initial plots

1) Describe the dataset, such that someone who happened upon this dataset could understand the variables and what they contain  
    i. Also consider whether any of the variables in _politeness_ should be encoded as factors or have the factor encoding removed. Hint: ```?factor```  
    
```{r}

glimpse(politeness)

# -> Subject = participant
# -> Gender = gender
# -> Scenario = condition (e.g. "apologising for being late", "asking a professor for an extension on an assignment" etc)
# -> Attitude = informal or formal (polite) conditions
# -> Total_duration = of sentence/saying, in seconds
# -> f0mn = mean of the f0, which is something to do with frequency (pitch??)
# -> hiss_count = audible and nasal hissing/air-sucking in between talking


politeness$subject <- as_factor(politeness$subject)
politeness$gender <- as_factor(politeness$gender)
politeness$attitude <- as_factor(politeness$attitude)

glimpse(politeness)

```


    
2) Create a new data frame that just contains the subject _F1_ and run two linear models; one that expresses _f0mn_ as dependent on _scenario_ as an integer; and one that expresses _f0mn_ as dependent on _scenario_ encoded as a factor  

```{r}

f1df <- politeness %>% 
  filter(subject=="F1")

hist(f1df$f0mn)
#This is not normal, is that ok?

f1df$scenario <- as.integer(f1df$scenario)
class(f1df$scenario)
model_1_2_integer <- lm(f0mn ~ scenario, data = f1df)
#How do we chose between lm, glm, lmer, glmer? This is repeated measures design, lm is bad.
#We start at the most basic level with lm

f1df$scenario <- as_factor(f1df$scenario)
class(f1df$scenario)
model_1_2_factor <- lm(f0mn ~ scenario, data = f1df)

#R should know that this is not an integer that it can do math with, it is a factor and 1 might as well be called "Talking to teacher"

```


    i. Include the model matrices, $X$ from the General Linear Model, for these two models in your report and describe the different interpretations of _scenario_ that these entail
    
```{r}

model.matrix(model_1_2_integer)
# The matrix shows the scenario as x-values, as a datapoint that has a corresponding y-value(the frequency). The number as the output/value from the scenario

model.matrix(model_1_2_factor)
# Here we see true/false, whether the trial is from the scenario or not. 

#The integer encoding treats the scenarios as 'scores' or data points — which is not the way the scenario number should be treated in this case. The factor encoding treats it like TRUE/FALSE and in this way, we can work with the scenario column as an experiment condition.
```

    ii. Which coding of _scenario_, as a factor or not, is more fitting?
    
```{r}

# Factor is more fitting, 1 is not a value but a name for a specific senario. Coding as an integer makes R interpret the data incorrectly.

```
    
    
3) Make a plot that includes a subplot for each subject that has _scenario_ on the x-axis and _f0mn_ on the y-axis and where points are colour coded according to _attitude_

```{r}
ggplot(data = politeness, aes(x = scenario, y = f0mn, color = attitude)) +
  geom_point() +
  facet_wrap(~ subject) +
  theme_bw()
```

    i. Describe the differences between subjects

```{r}
# Males have lower frequency than females
# Some people are not as affected by attitude as others
# Looking at F5 as an example, the scenario seem to have a bigger impact on voice than attitude
# For the hypotheses that Koreans lower their voices in formal conditions to hold, the red dots should be above the blue, which is hard to conclude anything from in the graphs, but might be true

```


    
## Exercise 2  - comparison of models

For this part, make sure to have `lme4` installed.  
You can install it using `install.packages("lme4")` and load it using `library(lme4)`  
`lmer` is used for multilevel modelling

```{r, eval=FALSE}
mixed.model <- lmer(formula=..., data=...)
example.formula <- formula(dep.variable ~ first.level.variable + (1 | second.level.variable))
```

1) Build four models and do some comparisons
    i. a single level model that models _f0mn_ as dependent on _gender_
    
```{r}

hist(politeness$f0mn)

ggplot(politeness, aes(sample=f0mn)) +
  stat_qq() +
  stat_qq_line(color = "red") +
  labs(x = "Theoretical Quantiles", y = "Sample Quantiles") +
  ggtitle("Q-Q Plot of politeness") +
  theme_minimal()
#Is it normal enough to model?

model_2_1 <- lm(f0mn ~ gender, data = politeness)
model_2_1

```
    
    
    ii. a two-level model that adds a second level on top of i. where unique intercepts are modelled for each _scenario_
```{r}
model_2_2 <- lmer(f0mn ~ gender + (1 | scenario), data = politeness)
model_2_2
```
    
    iii. a two-level model that only has _subject_ as an intercept 
```{r}
model_2_3 <- lmer(f0mn ~ gender + (1 | subject), data = politeness)
model_2_3
```
    
    iv. a two-level model that models intercepts for both _scenario_ and _subject_
    
```{r}
model_2_4 <- lmer(f0mn ~ gender + (1|subject) + (1|scenario), data = politeness)
 model_2_4
```
    
    
    v. which of the models has the lowest residual standard deviation, also compare the Akaike Information Criterion `AIC`?
    
```{r}

# Showing the residual standard deviation of each model 
sigma(model_2_1)

# Combining the residual standard deviation's into one table 
SD_comparison <- cbind(sigma(model_2_1), sigma(model_2_2), sigma(model_2_3), sigma(model_2_4)) 
SD_comparison

# Getting the AIC for each model 
AIC(logLik(model_2_1))

# Combinging the AIC's of all the models into one table
AIC_comparison <- cbind(AIC(logLik(model_2_1)), AIC(logLik(model_2_2)), AIC(logLik(model_2_3)), AIC(logLik(model_2_4))) 
AIC_comparison

```
    
    
    vi. which of the second-level effects explains the most variance?
    
```{r}

r.squaredGLMM(model_2_1)

r_squared_comparison <- cbind(r.squaredGLMM(model_2_1), r.squaredGLMM(model_2_2), r.squaredGLMM(model_2_3), r.squaredGLMM(model_2_4)) 
r_squared_comparison

# The fourth is the best

```
    
    
2) Why is our single-level model bad?
    i. create a new data frame that has three variables, _subject_, _gender_ and _f0mn_, where _f0mn_ is the average of all responses of each subject, i.e. averaging across (ignoring) _attitude_ and_scenario_
    
```{r}

simple_df <- politeness %>% 
  filter(!is.na(f0mn)) %>% 
  group_by(subject, gender) %>% 
  summarise(mean_f0mn = mean(f0mn))
simple_df

# There is so few N/A that we can kill them off in good faith

```
    
    
    ii. build a single-level model that models _f0mn_ as dependent on _gender_ using this new dataset
    
```{r}

model_2_5 <- lm(mean_f0mn ~ gender, data = simple_df)
model_2_5

```
    
    
    iii. make Quantile-Quantile plots, comparing theoretical quantiles to the sample quantiles) using `qqnorm` and `qqline` for the new single-level model and compare it to the old single-level model (from 1).i). Which model's residuals ($\epsilon$) fulfil the assumptions of the General Linear Model better?)
    
```{r}

qqnorm(residuals(model_2_1))
qqline(residuals(model_2_1))

qqnorm(residuals(model_2_5))
qqline(residuals(model_2_5))

#The model from 1i fits better, cause so many dots are on the line. ?

# Comparison between m1 and the new model from the new data frame: Very difficult to determine visually. model_2_1 has some weird outliers and is a bit curvy, but has many more datapoints that are completely on the line. model_2_5 has much fewer data points that aren't exactly on the line, but pretty close
# Buuut perhaps m1 is a little bit better, because it has sooo many points right on the line

```
    
    iv. Also make a quantile-quantile plot for the residuals of the  multilevel model with two intercepts. Does it look alright?
    
```{r}

qqnorm(residuals(model_2_4))
qqline(residuals(model_2_4))

```
    
    
3) Plotting the two-intercepts model
    i. Create a plot for each subject, (similar to part 3 in Exercise 1), this time also indicating the fitted value for each of the subjects for each for the scenarios (hint use `fixef` to get the "grand effects" for each gender and `ranef` to get the subject- and scenario-specific effects)
    
```{r}

fitted <- fitted(model_2_4)
politeness_na_removed <- politeness %>% 
  na.omit()
politeness_na_removed$fitted_f0mn <- fitted

ggplot(data = politeness_na_removed, aes(x = scenario, y = f0mn, color = attitude)) +
  geom_point() +
  geom_point(aes(scenario, fitted_f0mn), color = "black", shape = 17)+
  facet_wrap(~ subject) +
  theme_bw()

```
    
    
## Exercise 3 - now with attitude

1) Carry on with the model with the two unique intercepts fitted (_scenario_ and _subject_).
    i. now build a model that has _attitude_ as a main effect besides _gender_
```{r}
#Adding attitude as a main effect
model_3_1 <- lmer(f0mn ~ gender + attitude + (1 | scenario) + (1 | subject), data = politeness)
summary(model_3_1)
```
    
    ii. make a separate model that besides the main effects of _attitude_ and _gender_ also include their interaction
```{r}
#Adding the interaction of gender and attitude
model_3_2 <- lmer(f0mn ~ gender * attitude + (1 | scenario) + (1 | subject), data = politeness)
summary(model_3_2)
```
    iii. describe what the interaction term in the model says about Korean men's pitch when they are polite relative to Korean women's pitch when they are polite (you don't have to judge whether it is interesting)  

```{r}

# Men have a bigger gap in pitch when being informal compared to polite (seen in difference between slopes of genderM and genderM:attitudeinf). When Korean men are communicating informaly, their pitch is almost at the level of women's pitch when being polite. Korean women do not change their pitch as much when shifting between informal to polite communication.

```

    
2) Compare the three models (1. gender as a main effect; 2. gender and attitude as main effects; 3. gender and attitude as main effects and the interaction between them. For all three models model unique intercepts for _subject_ and _scenario_) using residual variance, residual standard deviation and AIC.  
```{r}
#Is R^2 the residual variance?
r.squaredGLMM(model_3_1)
r.squaredGLMM(model_3_2)

#Residual standard deviation
sigma(model_3_1)
sigma(model_3_2)

#AIC
AIC1 <- AIC(logLik(model_3_1))
AIC2 <- AIC(logLik(model_3_2))
```

3)  Choose the model that you think describe the data the best - and write a short report on the main findings based on this model. At least include the following:
  i. describe what the dataset consists of  
  
```{r}

#Data for this report is taken from Winter & Grawunder (2012)’s research article ‘The phonetic profile of Korean formal and informal speech registers’. In this dataset, the following variables are used:
#Participants are given numbers and their gender is recorded (Subject and gender variables). The study created different conditions, which are recorded as “Scenario”, in which participants were to make up a response to different scenarios, e.g. “apologising to a professor for being late”, “making a doctors appointment” etc. and could both be formal (e.g. talking to a boss or professor) or informal (talking to a friend). Formal and informal speech was recorded as attitude, where formal speech was denoted as “pol” (polite) and informal as “inf”. The duration of the sentences was recorded in seconds as Tota_durations. Two vocal factors were recorded, f0mn, the mean frequency of the voice and hiss_count, the audible hisses/air-sucking in between talking.

```
  
  
  ii. what can you conclude about the effect of gender and attitude on pitch (if anything)? 
  
```{r}

#Males have lower pitch than females, being polite lowers pitch

```
  
  
  iii. motivate why you would include separate intercepts for subjects and scenarios (if you think they should be included)  
  
```{r}

# separate intercepts for subjects are needed due to individual differences in baseline pitch
# separate intercepts for scenarios are needed as we can't directly compare across all polite conditions as the scenarios wary and affect the participants in different ways. Adding the intercept should explain more variance.

```
  
  iv. describe the variance components of the second level (if any) 
  
```{r}

summary(model_3_2)

# Scaled residuals: 
#     Min      1Q  Median      3Q     Max 
# -2.8120 -0.5884 -0.0645  0.4014  3.9100 

# Random effects:
#  Groups   Name        Variance Std.Dev.
#  subject  (Intercept) 584.4    24.17   
#  scenario (Intercept) 106.4    10.32   
#  Residual             885.5    29.76   
# Number of obs: 212, groups:  subject, 16; scenario, 7

```
  
  v. include a Quantile-Quantile plot of your chosen model  
  
```{r}

qqnorm(residuals(model_3_2))
qqline(residuals(model_3_2))

```

